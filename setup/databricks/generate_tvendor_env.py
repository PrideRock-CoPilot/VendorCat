from __future__ import annotations

import argparse
import os
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any
from urllib.parse import urlparse


def _parse_fq_schema(value: str) -> tuple[str, str]:
    raw = str(value or "").strip()
    parts = [item.strip() for item in raw.split(".", 1)]
    if len(parts) != 2 or not parts[0] or not parts[1]:
        raise ValueError("Expected --fq-schema in '<catalog>.<schema>' format.")
    return parts[0], parts[1]


def _clean_host(value: str) -> str:
    raw = str(value or "").strip()
    if not raw:
        return ""
    if "://" in raw:
        parsed = urlparse(raw)
        raw = parsed.netloc or parsed.path
    return raw.replace("https://", "").replace("http://", "").rstrip("/")


def _workspace_host_from_env() -> str:
    for key in ("DATABRICKS_SERVER_HOSTNAME", "DATABRICKS_HOST"):
        candidate = _clean_host(os.getenv(key, ""))
        if candidate:
            return candidate
    return ""


def _workspace_host_from_spark() -> str:
    try:
        from pyspark.sql import SparkSession  # type: ignore
    except Exception:
        return ""

    spark = SparkSession.getActiveSession()
    if spark is None:
        return ""
    try:
        return _clean_host(spark.conf.get("spark.databricks.workspaceUrl"))
    except Exception:
        return ""


def _workspace_host_from_dbutils() -> str:
    # Works when run in Databricks notebook Python context.
    try:
        dbutils_obj: Any = globals().get("dbutils")
        if dbutils_obj is None:
            return ""
        context = dbutils_obj.notebook.entry_point.getDbutils().notebook().getContext()
        try:
            api_url = context.apiUrl().getOrElse("")
            host = _clean_host(api_url)
            if host:
                return host
        except Exception:
            pass
        try:
            browser_host = context.browserHostName().getOrElse("")
            host = _clean_host(browser_host)
            if host:
                return host
        except Exception:
            pass
    except Exception:
        return ""
    return ""


def _detect_workspace_host() -> str:
    return _workspace_host_from_env() or _workspace_host_from_spark() or _workspace_host_from_dbutils()


def _resolve_http_path(http_path: str, warehouse_id: str) -> str:
    explicit = str(http_path or "").strip()
    if explicit:
        return explicit
    warehouse = str(warehouse_id or "").strip()
    if warehouse:
        return f"/sql/1.0/warehouses/{warehouse}"
    raise ValueError("Provide --http-path or --warehouse-id.")


def _build_env_text(
    *,
    env_name: str,
    host: str,
    http_path: str,
    warehouse_id: str,
    catalog: str,
    schema: str,
    fq_schema: str,
    oauth_client_id: str,
    oauth_client_secret: str,
    locked_mode: bool,
    port: int,
) -> str:
    timestamp = datetime.now(timezone.utc).isoformat()
    return "\n".join(
        [
            "# Vendor Catalog runtime + schema bootstrap configuration.",
            "# Generated by setup/databricks/generate_tvendor_env.py.",
            f"# Generated UTC timestamp: {timestamp}",
            "",
            "# Environment profile (dev/development/local/prod)",
            f"TVENDOR_ENV={env_name}",
            "",
            "# Runtime mode",
            "TVENDOR_USE_LOCAL_DB=false",
            "TVENDOR_LOCAL_DB_PATH=setup/local_db/twvendor_local.db",
            "TVENDOR_LOCAL_DB_SEED=false",
            "TVENDOR_LOCAL_DB_REBUILD_MODE=keep",
            f"TVENDOR_LOCKED_MODE={'true' if locked_mode else 'false'}",
            f"PORT={int(port)}",
            "",
            "# Databricks workspace connectivity",
            f"DATABRICKS_SERVER_HOSTNAME={host}",
            f"DATABRICKS_HTTP_PATH={http_path}",
            f"DATABRICKS_WAREHOUSE_ID={warehouse_id}",
            "# OAuth service principal (preferred for Databricks Apps)",
            "DATABRICKS_TOKEN=",
            f"DATABRICKS_CLIENT_ID={oauth_client_id}",
            f"DATABRICKS_CLIENT_SECRET={oauth_client_secret}",
            "",
            "# Target Unity Catalog objects used by the app",
            f"TVENDOR_FQ_SCHEMA={fq_schema}",
            f"TVENDOR_CATALOG={catalog}",
            f"TVENDOR_SCHEMA={schema}",
            "TVENDOR_ENFORCE_PROD_SQL_POLICY=true",
            "TVENDOR_ALLOWED_WRITE_VERBS=INSERT,UPDATE",
            "",
            "# Standalone schema bootstrap SQL (manual run only)",
            "TVENDOR_SCHEMA_BOOTSTRAP_SQL=setup/databricks/001_create_databricks_schema.sql",
            "",
        ]
    )


def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Generate setup/config/tvendor.env for Databricks + OAuth runtime."
    )
    parser.add_argument(
        "--fq-schema",
        required=True,
        help="Target '<catalog>.<schema>' (example: a1_dlk.twanalytics).",
    )
    parser.add_argument(
        "--workspace-hostname",
        default="",
        help="Databricks workspace hostname (auto-detected when omitted).",
    )
    parser.add_argument(
        "--http-path",
        default="",
        help="Databricks SQL HTTP path (overrides --warehouse-id when provided).",
    )
    parser.add_argument(
        "--warehouse-id",
        default=os.getenv("DATABRICKS_WAREHOUSE_ID", ""),
        help="Databricks SQL warehouse id; used to derive /sql/1.0/warehouses/<id>.",
    )
    parser.add_argument(
        "--oauth-client-id",
        default=os.getenv("DATABRICKS_CLIENT_ID", ""),
        help="OAuth service principal client id (optional at generation time).",
    )
    parser.add_argument(
        "--oauth-client-secret",
        default=os.getenv("DATABRICKS_CLIENT_SECRET", ""),
        help="OAuth service principal client secret (optional at generation time).",
    )
    parser.add_argument(
        "--env",
        default="prod",
        help="TVENDOR_ENV value (default: prod).",
    )
    parser.add_argument(
        "--locked-mode",
        action="store_true",
        help="Write TVENDOR_LOCKED_MODE=true.",
    )
    parser.add_argument(
        "--port",
        default=8000,
        type=int,
        help="PORT value for the app (default: 8000).",
    )
    parser.add_argument(
        "--output-file",
        default=str(Path(__file__).resolve().parents[1] / "config" / "tvendor.env"),
        help="Output env file path.",
    )
    parser.add_argument(
        "--bootstrap-admin",
        action="store_true",
        help=(
            "After writing env file, run schema validation + admin bootstrap "
            "via validate_schema_and_bootstrap_admin.py."
        ),
    )
    parser.add_argument(
        "--admin-principal",
        default="",
        help="Principal to bootstrap when --bootstrap-admin is used (default: current_user()).",
    )
    parser.add_argument(
        "--admin-roles",
        default="vendor_admin",
        help="Comma-separated roles for --bootstrap-admin (default: vendor_admin).",
    )
    parser.add_argument(
        "--admin-granted-by",
        default="",
        help="Grant actor for --bootstrap-admin (default: admin principal).",
    )
    parser.add_argument(
        "--bootstrap-dry-run",
        action="store_true",
        help="Validate only for --bootstrap-admin; skip writes.",
    )
    return parser.parse_args()


def main() -> int:
    args = _parse_args()
    try:
        catalog, schema = _parse_fq_schema(args.fq_schema)
        fq_schema = f"{catalog}.{schema}"
        host = _clean_host(args.workspace_hostname) or _detect_workspace_host()
        if not host:
            raise ValueError(
                "Unable to detect workspace host. Provide --workspace-hostname explicitly."
            )
        http_path = _resolve_http_path(args.http_path, args.warehouse_id)
        text = _build_env_text(
            env_name=str(args.env or "prod").strip().lower() or "prod",
            host=host,
            http_path=http_path,
            warehouse_id=str(args.warehouse_id or "").strip(),
            catalog=catalog,
            schema=schema,
            fq_schema=fq_schema,
            oauth_client_id=str(args.oauth_client_id or "").strip(),
            oauth_client_secret=str(args.oauth_client_secret or "").strip(),
            locked_mode=bool(args.locked_mode),
            port=int(args.port),
        )
    except ValueError as exc:
        print(f"ERROR: {exc}", file=sys.stderr)
        return 2

    output_path = Path(str(args.output_file or "").strip()).expanduser().resolve()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(text, encoding="utf-8")

    print(f"Wrote Databricks env config: {output_path}")
    print(f"TVENDOR_FQ_SCHEMA={fq_schema}")
    print(f"DATABRICKS_SERVER_HOSTNAME={host}")
    print(f"DATABRICKS_HTTP_PATH={http_path}")
    print("DATABRICKS_TOKEN is intentionally blank (OAuth-only mode).")

    if args.bootstrap_admin:
        bootstrap_script = Path(__file__).resolve().parent / "validate_schema_and_bootstrap_admin.py"
        cmd = [
            sys.executable,
            str(bootstrap_script),
            "--fq-schema",
            fq_schema,
            "--roles",
            str(args.admin_roles or "vendor_admin"),
        ]
        if str(args.admin_principal or "").strip():
            cmd.extend(["--principal", str(args.admin_principal).strip()])
        if str(args.admin_granted_by or "").strip():
            cmd.extend(["--granted-by", str(args.admin_granted_by).strip()])
        if args.bootstrap_dry_run:
            cmd.append("--dry-run")
        print("Running schema validation and admin bootstrap...")
        try:
            subprocess.run(cmd, check=True)
        except subprocess.CalledProcessError as exc:
            print(
                f"ERROR: Admin bootstrap failed with exit code {exc.returncode}.",
                file=sys.stderr,
            )
            return exc.returncode or 1

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
