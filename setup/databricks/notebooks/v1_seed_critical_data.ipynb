{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "v1_seed_critical_md_01",
                "language": "markdown"
            },
            "source": [
                "# V1 Critical Seed (Databricks)\n",
                "\n",
                "Seeds only POC-critical data:\n",
                "- dropdown/default lookup options\n",
                "- Help Center content\n",
                "\n",
                "This notebook intentionally skips the full synthetic test seed."
            ],
            "id": "v1_seed_critical_md_01"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "v1_seed_critical_code_01",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "dbutils.widgets.text('catalog', 'vendorcat_dev')\n",
                "dbutils.widgets.text('schema', 'vendorcat_v1')\n",
                "dbutils.widgets.text('seed_sql_root', '/Workspace/Repos/PrideRock-CoPilot/VendorCat/setup/v1_schema/databricks')\n",
                "\n",
                "catalog = dbutils.widgets.get('catalog').strip()\n",
                "schema = dbutils.widgets.get('schema').strip()\n",
                "seed_sql_root = dbutils.widgets.get('seed_sql_root').strip()\n",
                "\n",
                "assert catalog, 'catalog parameter is required'\n",
                "assert schema, 'schema parameter is required'\n",
                "assert seed_sql_root, 'seed_sql_root parameter is required'\n",
                "\n",
                "spark.sql(f\"USE CATALOG `{catalog}`\")\n",
                "spark.sql(f\"USE SCHEMA `{schema}`\")\n",
                "print(f'Seeding critical data for catalog={catalog} schema={schema}')\n",
                "print(f'SQL root: {seed_sql_root}')"
            ],
            "id": "v1_seed_critical_code_01"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "v1_seed_critical_code_02",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "import re\n",
                "from pathlib import Path\n",
                "\n",
                "token_pattern = re.compile(r'\\$\\{(CATALOG|SCHEMA)\\}')\n",
                "\n",
                "def render_sql(sql_text: str, catalog_name: str, schema_name: str) -> str:\n",
                "    context = {'CATALOG': catalog_name, 'SCHEMA': schema_name}\n",
                "    return token_pattern.sub(lambda m: context[m.group(1)], sql_text)\n",
                "\n",
                "def execute_sql_script(file_path: str) -> None:\n",
                "    path = Path(file_path)\n",
                "    if not path.exists():\n",
                "        raise FileNotFoundError(f'SQL file not found: {file_path}')\n",
                "    raw = path.read_text(encoding='utf-8')\n",
                "    rendered = render_sql(raw, catalog, schema)\n",
                "    statements = [stmt.strip() for stmt in rendered.split(';') if stmt.strip()]\n",
                "    for statement in statements:\n",
                "        spark.sql(statement)\n",
                "    print(f'Applied {path.name} ({len(statements)} statements)')"
            ],
            "id": "v1_seed_critical_code_02"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "v1_seed_critical_code_03",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "seed_files = [\n",
                "    f'{seed_sql_root}/94_seed_critical_reference_data.sql',\n",
                "    f'{seed_sql_root}/96_seed_help_center.sql',\n",
                "]\n",
                "\n",
                "for sql_file in seed_files:\n",
                "    execute_sql_script(sql_file)\n",
                "\n",
                "print('Critical seed completed.')"
            ],
            "id": "v1_seed_critical_code_03"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "v1_seed_critical_code_04",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "validation_queries = {\n",
                "    'lookup_options': 'SELECT COUNT(*) AS c FROM app_lookup_option',\n",
                "    'help_articles': 'SELECT COUNT(*) AS c FROM vendor_help_article',\n",
                "    'help_feedback': 'SELECT COUNT(*) AS c FROM vendor_help_feedback',\n",
                "    'help_issues': 'SELECT COUNT(*) AS c FROM vendor_help_issue',\n",
                "}\n",
                "\n",
                "for name, sql_text in validation_queries.items():\n",
                "    count = spark.sql(sql_text).collect()[0][0]\n",
                "    print(f'{name}: {count}')"
            ],
            "id": "v1_seed_critical_code_04"
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
