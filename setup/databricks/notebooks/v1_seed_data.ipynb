{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "9edad4a4",
                "language": "markdown"
            },
            "source": [
                "# V1 Data Seed (Databricks)\n",
                "\n",
                "Seeds the full synthetic functional test dataset into the V1 schema.\n",
                "Use this only for deep testing. For POC/demo-only seed, use `v1_seed_critical_data.ipynb`.\n",
                "This notebook executes the SQL assets in `setup/v1_schema/databricks/95_seed_reference_data.sql` and `96_seed_help_center.sql`."
            ],
            "id": "9edad4a4"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "ef2d3004",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "dbutils.widgets.text('catalog', 'vendorcat_dev')\n",
                "dbutils.widgets.text('schema', 'vendorcat_v1')\n",
                "dbutils.widgets.text('seed_sql_root', '/Workspace/Repos/PrideRock-CoPilot/VendorCat/setup/v1_schema/databricks')\n",
                "\n",
                "catalog = dbutils.widgets.get('catalog').strip()\n",
                "schema = dbutils.widgets.get('schema').strip()\n",
                "seed_sql_root = dbutils.widgets.get('seed_sql_root').strip()\n",
                "\n",
                "assert catalog, 'catalog parameter is required'\n",
                "assert schema, 'schema parameter is required'\n",
                "assert seed_sql_root, 'seed_sql_root parameter is required'\n",
                "\n",
                "spark.sql(f\"USE CATALOG `{catalog}`\")\n",
                "spark.sql(f\"USE SCHEMA `{schema}`\")\n",
                "print(f'Seeding catalog={catalog} schema={schema}')\n",
                "print(f'SQL root: {seed_sql_root}')"
            ],
            "id": "ef2d3004"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "93c3c004",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "import re\n",
                "from pathlib import Path\n",
                "\n",
                "token_pattern = re.compile(r'\\$\\{(CATALOG|SCHEMA)\\}')\n",
                "\n",
                "def render_sql(sql_text: str, catalog_name: str, schema_name: str) -> str:\n",
                "    context = {'CATALOG': catalog_name, 'SCHEMA': schema_name}\n",
                "    return token_pattern.sub(lambda m: context[m.group(1)], sql_text)\n",
                "\n",
                "def execute_sql_script(file_path: str) -> None:\n",
                "    path = Path(file_path)\n",
                "    if not path.exists():\n",
                "        raise FileNotFoundError(f'SQL file not found: {file_path}')\n",
                "    raw = path.read_text(encoding='utf-8')\n",
                "    rendered = render_sql(raw, catalog, schema)\n",
                "    statements = [stmt.strip() for stmt in rendered.split(';') if stmt.strip()]\n",
                "    for statement in statements:\n",
                "        spark.sql(statement)\n",
                "    print(f'Applied {path.name} ({len(statements)} statements)')"
            ],
            "id": "93c3c004"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "f705ddf6",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "seed_files = [\n",
                "    f'{seed_sql_root}/95_seed_reference_data.sql',\n",
                "    f'{seed_sql_root}/96_seed_help_center.sql',\n",
                "]\n",
                "\n",
                "for sql_file in seed_files:\n",
                "    execute_sql_script(sql_file)\n",
                "\n",
                "print('V1 seed completed.')"
            ],
            "id": "f705ddf6"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "3735c47e",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "validation_queries = {\n",
                "    'vendors': 'SELECT COUNT(*) AS c FROM core_vendor',\n",
                "    'offerings': 'SELECT COUNT(*) AS c FROM core_vendor_offering',\n",
                "    'contracts': 'SELECT COUNT(*) AS c FROM core_contract',\n",
                "    'projects': 'SELECT COUNT(*) AS c FROM app_project',\n",
                "    'help_articles': 'SELECT COUNT(*) AS c FROM vendor_help_article',\n",
                "    'role_grants': 'SELECT COUNT(*) AS c FROM sec_user_role_map WHERE active_flag = true',\n",
                "}\n",
                "\n",
                "for name, sql_text in validation_queries.items():\n",
                "    count = spark.sql(sql_text).collect()[0][0]\n",
                "    print(f'{name}: {count}')"
            ],
            "id": "3735c47e"
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
