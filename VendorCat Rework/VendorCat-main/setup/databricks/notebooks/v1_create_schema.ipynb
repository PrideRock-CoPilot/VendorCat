{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "68ff85dc",
            "metadata": {
                "id": "68ff85dc",
                "language": "markdown"
            },
            "source": [
                "# V1 Schema Bootstrap (Databricks)\n",
                "\n",
                "This notebook creates the V1 schema using parameterized catalog/schema values.\n",
                "Each table is created in its own cell for traceability and rerun control."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59e5a85b",
            "metadata": {
                "id": "59e5a85b",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "def get_widget(name: str, default: str) -> str:\n",
                "    try:\n",
                "        value = dbutils.widgets.get(name)\n",
                "        if value is None or str(value).strip() == \"\":\n",
                "            raise ValueError(\"empty widget\")\n",
                "        return str(value).strip()\n",
                "    except Exception:\n",
                "        dbutils.widgets.text(name, default)\n",
                "        return dbutils.widgets.get(name).strip()\n",
                "\n",
                "catalog = get_widget(\"catalog\", \"vendorcat_dev\")\n",
                "schema = get_widget(\"schema\", \"vendorcat_v1\")\n",
                "environment = get_widget(\"environment\", \"dev\")\n",
                "\n",
                "spark.sql(f\"CREATE CATALOG IF NOT EXISTS `{catalog}`\")\n",
                "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS `{catalog}`.`{schema}`\")\n",
                "spark.sql(f\"USE CATALOG `{catalog}`\")\n",
                "spark.sql(f\"USE SCHEMA `{schema}`\")\n",
                "\n",
                "print(f\"Running V1 schema bootstrap for env={environment}, catalog={catalog}, schema={schema}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d4b9e404a8",
            "metadata": {
                "id": "d4b9e404a8",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS lkp_line_of_business (\n",
                "  lob_id STRING,\n",
                "  lob_code STRING,\n",
                "  lob_name STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  sort_order INT,\n",
                "  effective_from TIMESTAMP,\n",
                "  effective_to TIMESTAMP,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b4b315661",
            "metadata": {
                "id": "8b4b315661",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS lkp_service_type (\n",
                "  service_type_id STRING,\n",
                "  service_type_code STRING,\n",
                "  service_type_name STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  sort_order INT,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f9a8e81d84",
            "metadata": {
                "id": "f9a8e81d84",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS lkp_owner_role (\n",
                "  owner_role_id STRING,\n",
                "  owner_role_code STRING,\n",
                "  owner_role_name STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a7f57cb24",
            "metadata": {
                "id": "3a7f57cb24",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS lkp_contact_type (\n",
                "  contact_type_id STRING,\n",
                "  contact_type_code STRING,\n",
                "  contact_type_name STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ecb0a644d8",
            "metadata": {
                "id": "ecb0a644d8",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS lkp_lifecycle_state (\n",
                "  lifecycle_state_id STRING,\n",
                "  lifecycle_state_code STRING,\n",
                "  lifecycle_state_name STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f82eedcbfd",
            "metadata": {
                "id": "f82eedcbfd",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS lkp_risk_tier (\n",
                "  risk_tier_id STRING,\n",
                "  risk_tier_code STRING,\n",
                "  risk_tier_name STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8610e230c6",
            "metadata": {
                "id": "8610e230c6",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor (\n",
                "  vendor_id STRING,\n",
                "  legal_name STRING,\n",
                "  display_name STRING,\n",
                "  lifecycle_state_id STRING,\n",
                "  risk_tier_id STRING,\n",
                "  primary_lob_id STRING,\n",
                "  source_system STRING,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP,\n",
                "  updated_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ea978f0958",
            "metadata": {
                "id": "ea978f0958",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS offering (\n",
                "  offering_id STRING,\n",
                "  vendor_id STRING,\n",
                "  offering_name STRING,\n",
                "  lifecycle_state_id STRING,\n",
                "  primary_lob_id STRING,\n",
                "  primary_service_type_id STRING,\n",
                "  criticality_tier STRING,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP,\n",
                "  updated_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b971670529",
            "metadata": {
                "id": "b971670529",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_identifier (\n",
                "  vendor_identifier_id STRING,\n",
                "  vendor_id STRING,\n",
                "  source_system_code STRING,\n",
                "  source_vendor_key STRING,\n",
                "  identifier_type STRING,\n",
                "  is_primary_source BOOLEAN,\n",
                "  verification_status STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  first_seen_at TIMESTAMP,\n",
                "  last_seen_at TIMESTAMP,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "83df8fa89e",
            "metadata": {
                "id": "83df8fa89e",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS project (\n",
                "  project_id STRING,\n",
                "  project_name STRING,\n",
                "  lifecycle_state_id STRING,\n",
                "  primary_lob_id STRING,\n",
                "  target_date DATE,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP,\n",
                "  updated_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "111c535dd1",
            "metadata": {
                "id": "111c535dd1",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS project_offering_map (\n",
                "  project_offering_map_id STRING,\n",
                "  project_id STRING,\n",
                "  offering_id STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  ended_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c66ca5ecfa",
            "metadata": {
                "id": "c66ca5ecfa",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_lob_assignment (\n",
                "  assignment_id STRING,\n",
                "  vendor_id STRING,\n",
                "  lob_id STRING,\n",
                "  is_primary BOOLEAN,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  ended_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d68a640080",
            "metadata": {
                "id": "d68a640080",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS offering_lob_assignment (\n",
                "  assignment_id STRING,\n",
                "  offering_id STRING,\n",
                "  lob_id STRING,\n",
                "  is_primary BOOLEAN,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  ended_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "faf5e31a10",
            "metadata": {
                "id": "faf5e31a10",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_owner_assignment (\n",
                "  assignment_id STRING,\n",
                "  vendor_id STRING,\n",
                "  owner_role_id STRING,\n",
                "  user_principal STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  ended_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7525afd669",
            "metadata": {
                "id": "7525afd669",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS offering_owner_assignment (\n",
                "  assignment_id STRING,\n",
                "  offering_id STRING,\n",
                "  owner_role_id STRING,\n",
                "  user_principal STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  ended_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5bc270cbb9",
            "metadata": {
                "id": "5bc270cbb9",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS project_owner_assignment (\n",
                "  assignment_id STRING,\n",
                "  project_id STRING,\n",
                "  owner_role_id STRING,\n",
                "  user_principal STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  ended_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8950082d04",
            "metadata": {
                "id": "8950082d04",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_contact (\n",
                "  vendor_contact_id STRING,\n",
                "  vendor_id STRING,\n",
                "  contact_type_id STRING,\n",
                "  full_name STRING,\n",
                "  email STRING,\n",
                "  phone STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  ended_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2cb55da71f",
            "metadata": {
                "id": "2cb55da71f",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS offering_contact (\n",
                "  offering_contact_id STRING,\n",
                "  offering_id STRING,\n",
                "  contact_type_id STRING,\n",
                "  full_name STRING,\n",
                "  email STRING,\n",
                "  phone STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  ended_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09145eb745",
            "metadata": {
                "id": "09145eb745",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS change_request (\n",
                "  request_id STRING,\n",
                "  entity_type STRING,\n",
                "  entity_id STRING,\n",
                "  change_type STRING,\n",
                "  payload_json STRING,\n",
                "  request_status STRING,\n",
                "  created_at TIMESTAMP,\n",
                "  created_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b0dda6608",
            "metadata": {
                "id": "8b0dda6608",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_merge_event (\n",
                "  merge_id STRING,\n",
                "  survivor_vendor_id STRING,\n",
                "  merge_status STRING,\n",
                "  merge_reason STRING,\n",
                "  merge_method STRING,\n",
                "  confidence_score DOUBLE,\n",
                "  request_id STRING,\n",
                "  merged_at TIMESTAMP,\n",
                "  merged_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "851bff8ff6",
            "metadata": {
                "id": "851bff8ff6",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_merge_member (\n",
                "  merge_member_id STRING,\n",
                "  merge_id STRING,\n",
                "  vendor_id STRING,\n",
                "  member_role STRING,\n",
                "  source_system_code STRING,\n",
                "  source_vendor_key STRING,\n",
                "  pre_merge_display_name STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9d27066429",
            "metadata": {
                "id": "9d27066429",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_merge_snapshot (\n",
                "  snapshot_id STRING,\n",
                "  merge_id STRING,\n",
                "  vendor_id STRING,\n",
                "  snapshot_json STRING,\n",
                "  captured_at TIMESTAMP,\n",
                "  captured_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5fddc10910",
            "metadata": {
                "id": "5fddc10910",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_survivorship_decision (\n",
                "  decision_id STRING,\n",
                "  merge_id STRING,\n",
                "  field_name STRING,\n",
                "  chosen_vendor_id STRING,\n",
                "  chosen_value_text STRING,\n",
                "  decision_method STRING,\n",
                "  decision_note STRING,\n",
                "  decided_at TIMESTAMP,\n",
                "  decided_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eb92a07e5a",
            "metadata": {
                "id": "eb92a07e5a",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS change_event (\n",
                "  event_id STRING,\n",
                "  request_id STRING,\n",
                "  entity_type STRING,\n",
                "  entity_id STRING,\n",
                "  action STRING,\n",
                "  payload_json STRING,\n",
                "  created_at TIMESTAMP,\n",
                "  created_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3f6e2b1bd8",
            "metadata": {
                "id": "3f6e2b1bd8",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS schema_version (\n",
                "  version_num INT,\n",
                "  description STRING,\n",
                "  applied_at TIMESTAMP,\n",
                "  applied_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "074a1450d7",
            "metadata": {
                "id": "074a1450d7",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_user_directory (\n",
                "  user_id STRING,\n",
                "  login_identifier STRING,\n",
                "  email STRING,\n",
                "  network_id STRING,\n",
                "  employee_id STRING,\n",
                "  manager_id STRING,\n",
                "  first_name STRING,\n",
                "  last_name STRING,\n",
                "  display_name STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  created_at TIMESTAMP,\n",
                "  updated_at TIMESTAMP,\n",
                "  last_seen_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0c969618c",
            "metadata": {
                "id": "e0c969618c",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_user_settings (\n",
                "  setting_id STRING,\n",
                "  user_principal STRING,\n",
                "  setting_key STRING,\n",
                "  setting_value_json STRING,\n",
                "  updated_at TIMESTAMP,\n",
                "  updated_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "355aeb56f9",
            "metadata": {
                "id": "355aeb56f9",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_usage_log (\n",
                "  usage_event_id STRING,\n",
                "  user_principal STRING,\n",
                "  page_name STRING,\n",
                "  event_type STRING,\n",
                "  event_ts TIMESTAMP,\n",
                "  payload_json STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "874b6e686b",
            "metadata": {
                "id": "874b6e686b",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS sec_role_definition (\n",
                "  role_code STRING,\n",
                "  role_name STRING,\n",
                "  description STRING,\n",
                "  approval_level INT,\n",
                "  can_edit BOOLEAN,\n",
                "  can_report BOOLEAN,\n",
                "  can_direct_apply BOOLEAN,\n",
                "  active_flag BOOLEAN,\n",
                "  updated_at TIMESTAMP,\n",
                "  updated_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3ee3799d9e",
            "metadata": {
                "id": "3ee3799d9e",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS sec_role_permission (\n",
                "  role_code STRING,\n",
                "  object_name STRING,\n",
                "  action_code STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  updated_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fe08fa46d",
            "metadata": {
                "id": "4fe08fa46d",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS sec_user_role_map (\n",
                "  user_principal STRING,\n",
                "  role_code STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  granted_by STRING,\n",
                "  granted_at TIMESTAMP,\n",
                "  revoked_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0e5352d8d2",
            "metadata": {
                "id": "0e5352d8d2",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS sec_group_role_map (\n",
                "  group_principal STRING,\n",
                "  role_code STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  granted_by STRING,\n",
                "  granted_at TIMESTAMP,\n",
                "  revoked_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eeb6f2e094",
            "metadata": {
                "id": "eeb6f2e094",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS sec_user_org_scope (\n",
                "  user_principal STRING,\n",
                "  org_id STRING,\n",
                "  scope_level STRING,\n",
                "  active_flag BOOLEAN,\n",
                "  granted_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cd820656d1",
            "metadata": {
                "id": "cd820656d1",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS audit_entity_change (\n",
                "  change_event_id STRING,\n",
                "  entity_name STRING,\n",
                "  entity_id STRING,\n",
                "  action_type STRING,\n",
                "  before_json STRING,\n",
                "  after_json STRING,\n",
                "  actor_user_principal STRING,\n",
                "  event_ts TIMESTAMP,\n",
                "  request_id STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eecd607a6d",
            "metadata": {
                "id": "eecd607a6d",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS audit_workflow_event (\n",
                "  workflow_event_id STRING,\n",
                "  workflow_type STRING,\n",
                "  workflow_id STRING,\n",
                "  old_status STRING,\n",
                "  new_status STRING,\n",
                "  actor_user_principal STRING,\n",
                "  event_ts TIMESTAMP,\n",
                "  notes STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0887f8a805",
            "metadata": {
                "id": "0887f8a805",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS audit_access_event (\n",
                "  access_event_id STRING,\n",
                "  actor_user_principal STRING,\n",
                "  action_type STRING,\n",
                "  target_user_principal STRING,\n",
                "  target_role STRING,\n",
                "  event_ts TIMESTAMP,\n",
                "  notes STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1e6bb5a39e",
            "metadata": {
                "id": "1e6bb5a39e",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_help_article (\n",
                "  article_id STRING,\n",
                "  slug STRING,\n",
                "  title STRING,\n",
                "  section STRING,\n",
                "  article_type STRING,\n",
                "  role_visibility STRING,\n",
                "  content_md STRING,\n",
                "  owned_by STRING,\n",
                "  updated_at TIMESTAMP,\n",
                "  updated_by STRING,\n",
                "  created_at TIMESTAMP,\n",
                "  created_by STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "769442b331",
            "metadata": {
                "id": "769442b331",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_help_feedback (\n",
                "  feedback_id STRING,\n",
                "  article_id STRING,\n",
                "  article_slug STRING,\n",
                "  was_helpful BOOLEAN,\n",
                "  comment STRING,\n",
                "  user_principal STRING,\n",
                "  page_path STRING,\n",
                "  created_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "55f1c193e3",
            "metadata": {
                "id": "55f1c193e3",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vendor_help_issue (\n",
                "  issue_id STRING,\n",
                "  article_id STRING,\n",
                "  article_slug STRING,\n",
                "  issue_title STRING,\n",
                "  issue_description STRING,\n",
                "  page_path STRING,\n",
                "  user_principal STRING,\n",
                "  created_at TIMESTAMP\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8952fd5fae",
            "metadata": {
                "id": "8952fd5fae",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS src_ingest_batch (\n",
                "  batch_id STRING,\n",
                "  source_system STRING NOT NULL,\n",
                "  source_object STRING NOT NULL,\n",
                "  extract_ts STRING NOT NULL,\n",
                "  loaded_ts STRING NOT NULL,\n",
                "  row_count INT,\n",
                "  status STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "08eb83ba5f",
            "metadata": {
                "id": "08eb83ba5f",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS src_peoplesoft_vendor_raw (\n",
                "  batch_id STRING NOT NULL,\n",
                "  source_record_id STRING NOT NULL,\n",
                "  source_extract_ts STRING NOT NULL,\n",
                "  payload_json STRING NOT NULL,\n",
                "  ingested_at STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b90dc0dab",
            "metadata": {
                "id": "8b90dc0dab",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS src_zycus_vendor_raw (\n",
                "  batch_id STRING NOT NULL,\n",
                "  source_record_id STRING NOT NULL,\n",
                "  source_extract_ts STRING NOT NULL,\n",
                "  payload_json STRING NOT NULL,\n",
                "  ingested_at STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1bef0f7dd",
            "metadata": {
                "id": "a1bef0f7dd",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS src_spreadsheet_vendor_raw (\n",
                "  batch_id STRING NOT NULL,\n",
                "  source_record_id STRING NOT NULL,\n",
                "  source_extract_ts STRING NOT NULL,\n",
                "  file_name STRING NOT NULL,\n",
                "  payload_json STRING NOT NULL,\n",
                "  ingested_at STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6228411f49",
            "metadata": {
                "id": "6228411f49",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_vendor (\n",
                "  vendor_id STRING,\n",
                "  legal_name STRING NOT NULL,\n",
                "  display_name STRING,\n",
                "  lifecycle_state STRING NOT NULL,\n",
                "  owner_org_id STRING NOT NULL,\n",
                "  risk_tier STRING,\n",
                "  source_system STRING,\n",
                "  source_record_id STRING,\n",
                "  source_batch_id STRING,\n",
                "  source_extract_ts STRING,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "44ed5c8fd4",
            "metadata": {
                "id": "44ed5c8fd4",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_vendor_identifier (\n",
                "  vendor_identifier_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  identifier_type STRING NOT NULL,\n",
                "  identifier_value STRING NOT NULL,\n",
                "  is_primary INT NOT NULL,\n",
                "  country_code STRING,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "365319360d",
            "metadata": {
                "id": "365319360d",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_vendor_contact (\n",
                "  vendor_contact_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  contact_type STRING NOT NULL,\n",
                "  full_name STRING NOT NULL,\n",
                "  email STRING,\n",
                "  phone STRING,\n",
                "  active_flag INT NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b1a60c274e",
            "metadata": {
                "id": "b1a60c274e",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_vendor_org_assignment (\n",
                "  vendor_org_assignment_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  org_id STRING NOT NULL,\n",
                "  assignment_type STRING NOT NULL,\n",
                "  active_flag INT NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ccab864e22",
            "metadata": {
                "id": "ccab864e22",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_vendor_business_owner (\n",
                "  vendor_owner_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  owner_user_principal STRING NOT NULL,\n",
                "  owner_role STRING NOT NULL,\n",
                "  active_flag INT NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "71255f61a9",
            "metadata": {
                "id": "71255f61a9",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_vendor_offering (\n",
                "  offering_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  offering_name STRING NOT NULL,\n",
                "  offering_type STRING,\n",
                "  lob STRING,\n",
                "  service_type STRING,\n",
                "  lifecycle_state STRING NOT NULL,\n",
                "  criticality_tier STRING,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d6fa4a3ce",
            "metadata": {
                "id": "7d6fa4a3ce",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_offering_business_owner (\n",
                "  offering_owner_id STRING,\n",
                "  offering_id STRING NOT NULL,\n",
                "  owner_user_principal STRING NOT NULL,\n",
                "  owner_role STRING NOT NULL,\n",
                "  active_flag INT NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fdedc394e4",
            "metadata": {
                "id": "fdedc394e4",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_offering_contact (\n",
                "  offering_contact_id STRING,\n",
                "  offering_id STRING NOT NULL,\n",
                "  contact_type STRING NOT NULL,\n",
                "  full_name STRING NOT NULL,\n",
                "  email STRING,\n",
                "  phone STRING,\n",
                "  active_flag INT NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4377725189",
            "metadata": {
                "id": "4377725189",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_contract (\n",
                "  contract_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  offering_id STRING,\n",
                "  contract_number STRING,\n",
                "  contract_status STRING NOT NULL,\n",
                "  start_date STRING,\n",
                "  end_date STRING,\n",
                "  cancelled_flag INT NOT NULL,\n",
                "  annual_value DOUBLE,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b41a379a8",
            "metadata": {
                "id": "3b41a379a8",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_contract_event (\n",
                "  contract_event_id STRING,\n",
                "  contract_id STRING NOT NULL,\n",
                "  event_type STRING NOT NULL,\n",
                "  event_ts STRING NOT NULL,\n",
                "  reason_code STRING,\n",
                "  notes STRING,\n",
                "  actor_user_principal STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7275398999",
            "metadata": {
                "id": "7275398999",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_vendor_demo (\n",
                "  demo_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  offering_id STRING,\n",
                "  demo_date STRING NOT NULL,\n",
                "  overall_score DOUBLE,\n",
                "  selection_outcome STRING NOT NULL,\n",
                "  non_selection_reason_code STRING,\n",
                "  notes STRING,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1effe9e49",
            "metadata": {
                "id": "a1effe9e49",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_vendor_demo_score (\n",
                "  demo_score_id STRING,\n",
                "  demo_id STRING NOT NULL,\n",
                "  score_category STRING NOT NULL,\n",
                "  score_value DOUBLE NOT NULL,\n",
                "  weight DOUBLE,\n",
                "  comments STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "abc700e6f2",
            "metadata": {
                "id": "abc700e6f2",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS core_vendor_demo_note (\n",
                "  demo_note_id STRING,\n",
                "  demo_id STRING NOT NULL,\n",
                "  note_type STRING NOT NULL,\n",
                "  note_text STRING NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "769e7aa469",
            "metadata": {
                "id": "769e7aa469",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS hist_vendor (\n",
                "  vendor_hist_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  version_no INT NOT NULL,\n",
                "  valid_from_ts STRING NOT NULL,\n",
                "  valid_to_ts STRING,\n",
                "  is_current INT NOT NULL,\n",
                "  snapshot_json STRING NOT NULL,\n",
                "  changed_by STRING NOT NULL,\n",
                "  change_reason STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fb8c8335bd",
            "metadata": {
                "id": "fb8c8335bd",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS hist_vendor_offering (\n",
                "  vendor_offering_hist_id STRING,\n",
                "  offering_id STRING NOT NULL,\n",
                "  version_no INT NOT NULL,\n",
                "  valid_from_ts STRING NOT NULL,\n",
                "  valid_to_ts STRING,\n",
                "  is_current INT NOT NULL,\n",
                "  snapshot_json STRING NOT NULL,\n",
                "  changed_by STRING NOT NULL,\n",
                "  change_reason STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0d9afb01ff",
            "metadata": {
                "id": "0d9afb01ff",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS hist_contract (\n",
                "  contract_hist_id STRING,\n",
                "  contract_id STRING NOT NULL,\n",
                "  version_no INT NOT NULL,\n",
                "  valid_from_ts STRING NOT NULL,\n",
                "  valid_to_ts STRING,\n",
                "  is_current INT NOT NULL,\n",
                "  snapshot_json STRING NOT NULL,\n",
                "  changed_by STRING NOT NULL,\n",
                "  change_reason STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8dc930460a",
            "metadata": {
                "id": "8dc930460a",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_onboarding_request (\n",
                "  request_id STRING,\n",
                "  requestor_user_principal STRING NOT NULL,\n",
                "  vendor_name_raw STRING NOT NULL,\n",
                "  priority STRING,\n",
                "  status STRING NOT NULL,\n",
                "  submitted_at STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "61be0dde82",
            "metadata": {
                "id": "61be0dde82",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_vendor_change_request (\n",
                "  change_request_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  requestor_user_principal STRING NOT NULL,\n",
                "  change_type STRING NOT NULL,\n",
                "  requested_payload_json STRING NOT NULL,\n",
                "  status STRING NOT NULL,\n",
                "  submitted_at STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a17f61a41d",
            "metadata": {
                "id": "a17f61a41d",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_onboarding_task (\n",
                "  task_id STRING,\n",
                "  request_id STRING NOT NULL,\n",
                "  task_type STRING NOT NULL,\n",
                "  assignee_group STRING,\n",
                "  due_at STRING,\n",
                "  status STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c37f525f26",
            "metadata": {
                "id": "c37f525f26",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_onboarding_approval (\n",
                "  approval_id STRING,\n",
                "  request_id STRING NOT NULL,\n",
                "  stage_name STRING NOT NULL,\n",
                "  approver_user_principal STRING,\n",
                "  decision STRING,\n",
                "  decided_at STRING,\n",
                "  comments STRING,\n",
                "  updated_at STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "def397f85d",
            "metadata": {
                "id": "def397f85d",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_access_request (\n",
                "  access_request_id STRING,\n",
                "  requester_user_principal STRING NOT NULL,\n",
                "  requested_role STRING NOT NULL,\n",
                "  justification STRING,\n",
                "  status STRING NOT NULL,\n",
                "  submitted_at STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d563730938",
            "metadata": {
                "id": "d563730938",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_note (\n",
                "  note_id STRING,\n",
                "  entity_name STRING NOT NULL,\n",
                "  entity_id STRING NOT NULL,\n",
                "  note_type STRING NOT NULL,\n",
                "  note_text STRING NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "227e1407bd",
            "metadata": {
                "id": "227e1407bd",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_employee_directory (\n",
                "  login_identifier STRING,\n",
                "  email STRING NOT NULL,\n",
                "  network_id STRING,\n",
                "  employee_id STRING,\n",
                "  manager_id STRING,\n",
                "  first_name STRING,\n",
                "  last_name STRING,\n",
                "  display_name STRING NOT NULL,\n",
                "  active_flag INT NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a1eaadd1a",
            "metadata": {
                "id": "3a1eaadd1a",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_lookup_option (\n",
                "  option_id STRING,\n",
                "  lookup_type STRING NOT NULL,\n",
                "  option_code STRING NOT NULL,\n",
                "  option_label STRING NOT NULL,\n",
                "  sort_order INT NOT NULL,\n",
                "  active_flag INT NOT NULL,\n",
                "  valid_from_ts STRING NOT NULL,\n",
                "  valid_to_ts STRING,\n",
                "  is_current INT NOT NULL,\n",
                "  deleted_flag INT NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f9cb508823",
            "metadata": {
                "id": "f9cb508823",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_project (\n",
                "  project_id STRING,\n",
                "  vendor_id STRING,\n",
                "  project_name STRING NOT NULL,\n",
                "  project_type STRING,\n",
                "  status STRING NOT NULL,\n",
                "  start_date STRING,\n",
                "  target_date STRING,\n",
                "  owner_principal STRING,\n",
                "  description STRING,\n",
                "  active_flag INT NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7ebebd7728",
            "metadata": {
                "id": "7ebebd7728",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_project_vendor_map (\n",
                "  project_vendor_map_id STRING,\n",
                "  project_id STRING NOT NULL,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  active_flag INT NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a714455a4",
            "metadata": {
                "id": "0a714455a4",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_project_offering_map (\n",
                "  project_offering_map_id STRING,\n",
                "  project_id STRING NOT NULL,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  offering_id STRING NOT NULL,\n",
                "  active_flag INT NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c33a2ad94",
            "metadata": {
                "id": "3c33a2ad94",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_project_demo (\n",
                "  project_demo_id STRING,\n",
                "  project_id STRING NOT NULL,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  demo_name STRING NOT NULL,\n",
                "  demo_datetime_start STRING,\n",
                "  demo_datetime_end STRING,\n",
                "  demo_type STRING,\n",
                "  outcome STRING,\n",
                "  score DOUBLE,\n",
                "  attendees_internal STRING,\n",
                "  attendees_vendor STRING,\n",
                "  notes STRING,\n",
                "  followups STRING,\n",
                "  linked_offering_id STRING,\n",
                "  linked_vendor_demo_id STRING,\n",
                "  active_flag INT NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c2d002a0cb",
            "metadata": {
                "id": "c2d002a0cb",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_project_note (\n",
                "  project_note_id STRING,\n",
                "  project_id STRING NOT NULL,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  note_text STRING NOT NULL,\n",
                "  active_flag INT NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d52a487ea4",
            "metadata": {
                "id": "d52a487ea4",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_offering_profile (\n",
                "  offering_id STRING,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  estimated_monthly_cost DOUBLE,\n",
                "  implementation_notes STRING,\n",
                "  data_sent STRING,\n",
                "  data_received STRING,\n",
                "  integration_method STRING,\n",
                "  inbound_method STRING,\n",
                "  inbound_landing_zone STRING,\n",
                "  inbound_identifiers STRING,\n",
                "  inbound_reporting_layer STRING,\n",
                "  inbound_ingestion_notes STRING,\n",
                "  outbound_method STRING,\n",
                "  outbound_creation_process STRING,\n",
                "  outbound_delivery_process STRING,\n",
                "  outbound_responsible_owner STRING,\n",
                "  outbound_notes STRING,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4a437edfda",
            "metadata": {
                "id": "4a437edfda",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_offering_data_flow (\n",
                "  data_flow_id STRING,\n",
                "  offering_id STRING NOT NULL,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  direction STRING NOT NULL,\n",
                "  flow_name STRING NOT NULL,\n",
                "  method STRING,\n",
                "  data_description STRING,\n",
                "  endpoint_details STRING,\n",
                "  identifiers STRING,\n",
                "  reporting_layer STRING,\n",
                "  creation_process STRING,\n",
                "  delivery_process STRING,\n",
                "  owner_user_principal STRING,\n",
                "  notes STRING,\n",
                "  active_flag INT NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "67b8c9f4a3",
            "metadata": {
                "id": "67b8c9f4a3",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_offering_ticket (\n",
                "  ticket_id STRING,\n",
                "  offering_id STRING NOT NULL,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  ticket_system STRING,\n",
                "  external_ticket_id STRING,\n",
                "  title STRING NOT NULL,\n",
                "  status STRING NOT NULL,\n",
                "  priority STRING,\n",
                "  opened_date STRING,\n",
                "  closed_date STRING,\n",
                "  notes STRING,\n",
                "  active_flag INT NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19543e777a",
            "metadata": {
                "id": "19543e777a",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_offering_invoice (\n",
                "  invoice_id STRING,\n",
                "  offering_id STRING NOT NULL,\n",
                "  vendor_id STRING NOT NULL,\n",
                "  invoice_number STRING,\n",
                "  invoice_date STRING NOT NULL,\n",
                "  amount DOUBLE NOT NULL,\n",
                "  currency_code STRING NOT NULL,\n",
                "  invoice_status STRING NOT NULL,\n",
                "  notes STRING,\n",
                "  active_flag INT NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f907e8982c",
            "metadata": {
                "id": "f907e8982c",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS app_document_link (\n",
                "  doc_id STRING,\n",
                "  entity_type STRING NOT NULL,\n",
                "  entity_id STRING NOT NULL,\n",
                "  doc_title STRING NOT NULL,\n",
                "  doc_url STRING NOT NULL,\n",
                "  doc_type STRING NOT NULL,\n",
                "  tags STRING,\n",
                "  owner STRING,\n",
                "  active_flag INT NOT NULL,\n",
                "  created_at STRING NOT NULL,\n",
                "  created_by STRING NOT NULL,\n",
                "  updated_at STRING NOT NULL,\n",
                "  updated_by STRING NOT NULL\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3c5d4e14d",
            "metadata": {
                "id": "b3c5d4e14d",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "# Create vw_employee_directory as TABLE (not view) for dev/test environments\n",
                "# In production, replace this with actual view pointing to pr_std.hcm.emp_courion\n",
                "spark.sql(\"\"\"\n",
                "CREATE TABLE IF NOT EXISTS vw_employee_directory (\n",
                "  employee_id STRING,\n",
                "  login_identifier STRING,\n",
                "  network_id STRING,\n",
                "  email STRING,\n",
                "  first_name STRING,\n",
                "  last_name STRING,\n",
                "  display_name STRING,\n",
                "  active_flag STRING,\n",
                "  employment_status STRING,\n",
                "  last_action_date STRING,\n",
                "  hire_date STRING,\n",
                "  termination_date STRING,\n",
                "  job_title STRING,\n",
                "  department_name STRING,\n",
                "  manager_level STRING,\n",
                "  hierarchy_tier STRING,\n",
                "  default_security_level INT,\n",
                "  manager_id STRING\n",
                ") USING DELTA\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59c6dd9b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Seed employee directory with current user and sample data\n",
                "# Get current Databricks user\n",
                "current_user_result = spark.sql(\"SELECT current_user() as user\").collect()\n",
                "current_user = current_user_result[0]['user']\n",
                "\n",
                "# Parse user info\n",
                "user_parts = current_user.split('@')\n",
                "username = user_parts[0] if '@' in current_user else current_user\n",
                "email = current_user if '@' in current_user else f\"{current_user}@example.com\"\n",
                "\n",
                "# Try to split username into first/last name\n",
                "name_parts = username.replace('.', ' ').replace('_', ' ').split()\n",
                "if len(name_parts) >= 2:\n",
                "    first_name = name_parts[0].capitalize()\n",
                "    last_name = name_parts[-1].capitalize()\n",
                "else:\n",
                "    first_name = username.capitalize()\n",
                "    last_name = \"User\"\n",
                "\n",
                "display_name = f\"{first_name} {last_name}\"\n",
                "\n",
                "print(f\"Seeding employee directory with current user: {display_name} ({email})\")\n",
                "\n",
                "# Insert current user as admin\n",
                "spark.sql(f\"\"\"\n",
                "INSERT INTO `{catalog}`.`{schema}`.vw_employee_directory VALUES\n",
                "  ('EMP001', '{email.lower()}', '{email.lower()}', '{email}', \n",
                "   '{first_name}', '{last_name}', '{display_name}',\n",
                "   'A', 'Active', \n",
                "   current_timestamp(), '2020-01-15', NULL,\n",
                "   'System Administrator', 'IT Operations',\n",
                "   '1', 'Director', 8, NULL)\n",
                "\"\"\")\n",
                "\n",
                "# Add sample employees for testing\n",
                "spark.sql(f\"\"\"\n",
                "INSERT INTO `{catalog}`.`{schema}`.vw_employee_directory VALUES\n",
                "  ('EMP002', 'john.smith@example.com', 'john.smith@example.com', 'john.smith@example.com',\n",
                "   'John', 'Smith', 'John Smith',\n",
                "   'A', 'Active',\n",
                "   current_timestamp(), '2019-03-20', NULL,\n",
                "   'Vendor Manager', 'Procurement',\n",
                "   '5', 'Manager', 4, 'EMP001'),\n",
                "  ('EMP003', 'jane.doe@example.com', 'jane.doe@example.com', 'jane.doe@example.com',\n",
                "   'Jane', 'Doe', 'Jane Doe',\n",
                "   'A', 'Active',\n",
                "   current_timestamp(), '2021-06-10', NULL,\n",
                "   'Senior Analyst', 'Finance',\n",
                "   '2', 'Senior Partner / Specialist', 4, 'EMP002'),\n",
                "  ('EMP004', 'mike.johnson@example.com', 'mike.johnson@example.com', 'mike.johnson@example.com',\n",
                "   'Mike', 'Johnson', 'Mike Johnson',\n",
                "   'A', 'Active',\n",
                "   current_timestamp(), '2018-11-05', NULL,\n",
                "   'VP Procurement', 'Procurement',\n",
                "   '3', 'VP', 8, NULL),\n",
                "  ('EMP005', 'sarah.williams@example.com', 'sarah.williams@example.com', 'sarah.williams@example.com',\n",
                "   'Sarah', 'Williams', 'Sarah Williams',\n",
                "   'A', 'Active',\n",
                "   current_timestamp(), '2020-09-15', NULL,\n",
                "   'Contract Specialist', 'Legal',\n",
                "   '9', 'Individual Contributor', 2, 'EMP002')\n",
                "\"\"\")\n",
                "\n",
                "row_count = spark.sql(f\"SELECT COUNT(*) as cnt FROM `{catalog}`.`{schema}`.vw_employee_directory\").collect()[0]['cnt']\n",
                "print(f\"Employee directory seeded with {row_count} records\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3114b0b623",
            "metadata": {
                "id": "3114b0b623",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE OR REPLACE VIEW rpt_spend_fact AS\n",
                "SELECT\n",
                "  i.invoice_id,\n",
                "  i.vendor_id,\n",
                "  COALESCE(v.display_name, v.legal_name) AS vendor_name,\n",
                "  v.owner_org_id AS org_id,\n",
                "  COALESCE(o.offering_type, 'unknown') AS category,\n",
                "  i.invoice_date AS month,\n",
                "  i.amount\n",
                "FROM app_offering_invoice i\n",
                "LEFT JOIN core_vendor v\n",
                "  ON i.vendor_id = v.vendor_id\n",
                "LEFT JOIN core_vendor_offering o\n",
                "  ON i.offering_id = o.offering_id\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d50c5cd9ff",
            "metadata": {
                "id": "d50c5cd9ff",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE OR REPLACE VIEW rpt_contract_renewals AS\n",
                "SELECT\n",
                "  c.contract_id,\n",
                "  c.vendor_id,\n",
                "  COALESCE(v.display_name, v.legal_name) AS vendor_name,\n",
                "  v.owner_org_id AS org_id,\n",
                "  COALESCE(o.offering_type, 'unknown') AS category,\n",
                "  c.end_date AS renewal_date,\n",
                "  c.annual_value,\n",
                "  v.risk_tier,\n",
                "  CASE\n",
                "    WHEN c.cancelled_flag = true THEN 'cancelled'\n",
                "    ELSE c.contract_status\n",
                "  END AS renewal_status\n",
                "FROM core_contract c\n",
                "LEFT JOIN core_vendor v\n",
                "  ON c.vendor_id = v.vendor_id\n",
                "LEFT JOIN core_vendor_offering o\n",
                "  ON c.offering_id = o.offering_id\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "890c8311c2",
            "metadata": {
                "id": "890c8311c2",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "spark.sql(\"\"\"\n",
                "CREATE OR REPLACE VIEW rpt_contract_cancellations AS\n",
                "SELECT\n",
                "  c.contract_id,\n",
                "  c.vendor_id,\n",
                "  c.offering_id,\n",
                "  e.event_ts AS cancelled_at,\n",
                "  e.reason_code,\n",
                "  e.notes\n",
                "FROM core_contract c\n",
                "INNER JOIN core_contract_event e\n",
                "  ON c.contract_id = e.contract_id\n",
                "WHERE lower(COALESCE(e.event_type, '')) IN ('cancelled', 'cancellation', 'contract_cancelled')\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e26ee989",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Enable column defaults feature and set defaults\n",
                "# First enable the delta.feature.allowColumnDefaults property, then set defaults\n",
                "\n",
                "tables_with_defaults = [\n",
                "    \"core_vendor_identifier\",\n",
                "    \"core_vendor_contact\",\n",
                "    \"core_vendor_org_assignment\",\n",
                "    \"core_vendor_business_owner\",\n",
                "    \"core_offering_business_owner\",\n",
                "    \"core_offering_contact\",\n",
                "    \"core_contract\",\n",
                "    \"hist_vendor\",\n",
                "    \"hist_vendor_offering\",\n",
                "    \"hist_contract\",\n",
                "    \"app_employee_directory\",\n",
                "    \"app_lookup_option\",\n",
                "    \"app_project\",\n",
                "    \"app_project_vendor_map\",\n",
                "    \"app_project_offering_map\",\n",
                "    \"app_project_demo\",\n",
                "    \"app_project_note\",\n",
                "    \"app_offering_data_flow\",\n",
                "    \"app_offering_ticket\",\n",
                "    \"app_offering_invoice\",\n",
                "    \"app_document_link\"\n",
                "]\n",
                "\n",
                "# Enable column defaults feature on all relevant tables\n",
                "for table in tables_with_defaults:\n",
                "    spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.{table} SET TBLPROPERTIES ('delta.feature.allowColumnDefaults' = 'supported')\")\n",
                "\n",
                "print(f\"Enabled allowColumnDefaults feature for {len(tables_with_defaults)} tables\")\n",
                "\n",
                "# Now set the default values\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.core_vendor_identifier ALTER COLUMN is_primary SET DEFAULT 0\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.core_vendor_contact ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.core_vendor_org_assignment ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.core_vendor_business_owner ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.core_offering_business_owner ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.core_offering_contact ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.core_contract ALTER COLUMN cancelled_flag SET DEFAULT 0\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.hist_vendor ALTER COLUMN is_current SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.hist_vendor_offering ALTER COLUMN is_current SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.hist_contract ALTER COLUMN is_current SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_employee_directory ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_lookup_option ALTER COLUMN sort_order SET DEFAULT 100\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_lookup_option ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_lookup_option ALTER COLUMN is_current SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_lookup_option ALTER COLUMN deleted_flag SET DEFAULT 0\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_project ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_project_vendor_map ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_project_offering_map ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_project_demo ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_project_note ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_offering_data_flow ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_offering_ticket ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_offering_invoice ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.app_document_link ALTER COLUMN active_flag SET DEFAULT 1\")\n",
                "\n",
                "print(f\"Default constraints set for {catalog}.{schema}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e70d8ffa",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Grant permissions to app service principal\n",
                "from databricks.sdk import WorkspaceClient\n",
                "\n",
                "# Get parameters\n",
                "app_name = get_widget(\"app_name\", \"vendorcatalog\")\n",
                "\n",
                "print(f\"[1/4] Getting service principal for app: {app_name}\")\n",
                "\n",
                "sp_principal = None\n",
                "try:\n",
                "    w = WorkspaceClient()\n",
                "    app = w.apps.get(name=app_name)\n",
                "    sp_display_name = app.service_principal_name\n",
                "    sp_id = app.service_principal_id\n",
                "    \n",
                "    # Get the actual service principal to find the correct identifier\n",
                "    print(f\"  Found: {sp_display_name} (ID: {sp_id})\")\n",
                "    print(f\"  Fetching service principal details...\")\n",
                "    \n",
                "    sp = w.service_principals.get(id=str(sp_id))\n",
                "    # Use applicationId for Unity Catalog grants (format: 12345678-1234-1234-1234-123456789abc)\n",
                "    sp_principal = sp.application_id\n",
                "    print(f\"SUCCESS: Service Principal identifier: {sp_principal}\")\n",
                "except Exception as e:\n",
                "    print(f\"ERROR: Could not get service principal: {e}\")\n",
                "    print(\"Skipping permission grants. Run grant_service_principal_permissions.ps1 manually.\")\n",
                "    sp_principal = None\n",
                "\n",
                "if sp_principal:\n",
                "    print(f\"\\n[2/4] Granting catalog permissions...\")\n",
                "    try:\n",
                "        spark.sql(f\"GRANT USE_CATALOG ON CATALOG `{catalog}` TO `{sp_principal}`\")\n",
                "        print(f\"SUCCESS: Granted USE_CATALOG on {catalog}\")\n",
                "    except Exception as e:\n",
                "        print(f\"WARNING: Could not grant USE_CATALOG: {e}\")\n",
                "    \n",
                "    print(f\"\\n[3/4] Granting schema permissions...\")\n",
                "    try:\n",
                "        spark.sql(f\"GRANT USE_SCHEMA ON SCHEMA `{catalog}`.`{schema}` TO `{sp_principal}`\")\n",
                "        spark.sql(f\"GRANT MODIFY ON SCHEMA `{catalog}`.`{schema}` TO `{sp_principal}`\")\n",
                "        print(f\"SUCCESS: Granted USE_SCHEMA and MODIFY on {catalog}.{schema}\")\n",
                "    except Exception as e:\n",
                "        print(f\"WARNING: Could not grant schema permissions: {e}\")\n",
                "    \n",
                "    print(f\"\\n[4/4] Granting table permissions...\")\n",
                "    tables_result = spark.sql(f\"SHOW TABLES IN `{catalog}`.`{schema}`\").collect()\n",
                "    table_count = 0\n",
                "    failed_count = 0\n",
                "    for row in tables_result:\n",
                "        table_name = row['tableName']\n",
                "        try:\n",
                "            spark.sql(f\"GRANT SELECT ON TABLE `{catalog}`.`{schema}`.`{table_name}` TO `{sp_principal}`\")\n",
                "            table_count += 1\n",
                "        except Exception as e:\n",
                "            print(f\"WARNING: Could not grant SELECT on {table_name}: {e}\")\n",
                "            failed_count += 1\n",
                "    \n",
                "    print(f\"SUCCESS: Granted SELECT on {table_count} tables\" + (f\" ({failed_count} failed)\" if failed_count > 0 else \"\"))\n",
                "    \n",
                "    print(f\"\\n\" + \"=\"*50)\n",
                "    print(f\"Permission grants complete!\")\n",
                "    print(f\"Service Principal ID: {sp_principal}\")\n",
                "    print(f\"Catalog/Schema: {catalog}.{schema}\")\n",
                "    print(f\"Tables: {table_count}\")\n",
                "    print(\"=\"*50)\n",
                "else:\n",
                "    print(\"\\n\" + \"=\"*50)\n",
                "    print(\"No service principal configured.\")\n",
                "    print(\"To grant permissions manually, run:\")\n",
                "    print(\"  .\\\\setup\\\\databricks\\\\grant_service_principal_permissions.ps1\")\n",
                "    print(\"=\"*50)"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
